---
title: "Ejercicios Tema 2 - Estimación. Taller 3"
author: "Ricardo Alberich, Juan Gabriel Gomila y Arnau Mir"
date: "Curso completo de estadística inferencial con R y Python"
output:
  pdf_document:
    number_sections: yes
    toc: yes
  html_document:
    df_print: paged
    toc: yes
toccolor: blue
linkcolor: red
header-includes: \renewcommand{\contentsname}{Contenidos}
citecolor: blue
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Estimación taller 3

## Ejercicio 1
Supongamos  que $X_1,X_2,\ldots,X_6$ es una muestra aleatoria de una
variable aleatoria normal con media  $\mu$ y  varianza $\sigma^2$.
 Hallar  la constante $C$ tal que $$C\cdot\bigl({(X_1 -X_2)}^2 +{(X_3 -X_4)}^2 + 
 {(X_5 -X_6)}^2\bigr),$$ sea  un estimador sin sesgo de $\sigma^2$.


## Ejercicio 2
Supongamos  que $\Theta_1$ y  $\Theta_2$ son estimadores sin sesgo
de un parámetro desconocido $\theta$, con varianzas conocidas $\sigma_1^2$ y
$\sigma_2^2$, respectivamente. Demostrar  que $\Theta =(1-a)\cdot\Theta_1 +a\cdot \Theta_2$ también es insesgado para cualquier valor de $a\not=0$.





## Ejercicio 3
Sea $X_1,\ldots,X_{2n}$ una muestra aleatoria simple de una variable
aleatoria $N(\mu,\sigma)$. Sea:
\[
T=C\left({\left(\sum_{i=1}^{2n} X_i\right)}^2- 4 n\sum_{i=1}^{n}
X_{2i} X_{2i-1}\right)
\]
un estimador del parámetro $\sigma^2$. ¿Cuál es el valor de $C$ para que 
$T$ sea un estimador insesgado?

## Ejercicio 4
Una variable aleatoria $X$ sigue la  distribución de 
Rayleigh con parámetro $\theta >0$ si es una variable 
aleatoria con valores $x>0$ y  función  de densidad:
$$
f(x)=\frac{x}{\theta} e^{-\frac{x^2}{2\theta}}.
$$

> Hallar estimadores del parámetro $\theta$:

>>   a.) El método de los momentos.

>>   b.) El método de la máxima  verosimilitud.

## Ejercicio 5
Sea $X$ una variable aleatoria tal que $E(X)=\mu$ y  $Var(X)=\sigma^2$. Sea $X_1,X_2$ una muestra aleatoria simple de $X$ de
tamaño $2$. Consideremos el siguiente estimador del parámetro $\mu$:
$\tilde{\mu}=2 a X_1 + (1-2 a) X_2$.  Hallar el valor de $a$ que hace que el estadístico  
$\tilde{\mu}$ sea el más eficiente posible.


# Soluciones

## Solución ejercicio 1
Recordemos que $E(X_i)=\mu$,  y que $\sigma^2=E(X_i^2)-\left(E(X_i)\right)^2=E(X_i^2)-\mu^2$ luego $E(X_i^2)=\sigma^2+\mu^2$ para $i=1,2,3$. Además al ser independientes  
$E(X_1\cdot X_{2})=E(X_1)\cdot E(X_2)\mu\cdot\mu=\mu^2$  y lo mismo para  $E(X_3\cdot X_{4})=E(X_5\cdot X_{6})=\mu^2.$

Ahora

$$
\begin{array}{rl}
E\left(\left(X_{1}-X_{2}\right)^2\right) & =
E\left(X_{1}^2-2\cdot X_1\cdot X_{2}+X_{2}^2\right)\\
& = E\left(X_{1}^2\right)-2\cdot E(X_1\cdot X_{2})+E\left(X_{2}^2\right)\\
& = (\sigma^2+\mu^2)-2\cdot (\mu\cdot\mu)+ (\sigma^2+\mu^2)\\
& =2\cdot\sigma^2. 
\end{array}
$$


Utilizando adecuadamente los cálculos anteriores
$$
E\left(C\cdot\bigl({(X_1 -X_2)}^2 +{(X_3 -X_4)}^2 + {(X_5 -X_6)}^2\bigr)\right)=C\cdot 3\cdot 2\cdot \sigma^2.
$$

Luego el valor de $C$ para que el estimador sea insesgado es  la solución de la ecuación 

$$C\cdot 3\cdot 2\cdot \sigma^2=\sigma^2$$

Así que el valor buscado es $C=\frac16.$ 


## Solución ejercicio 2

Supongamos  que $\Theta_1$ y  $\Theta_2$ son estimadores sin sesgo
de un parámetro desconocido $\theta$, con varianzas conocidas $\sigma_1^2$ y
$\sigma_2^2$, respectivamente. Demostrar  que $\Theta =(1-a)\cdot\Theta_1 +a\cdot \Theta_2$ también es insesgado para cualquier valor de $a$.



Tenemos que $E(\Theta_1)=E(\Theta_2)=\theta$ y que $Var(\Theta_1)=\sigma_1$ y $Var(\Theta_2)=\sigma_2$.

Nos piden que demostremos que  para cualquier $a\not=0$

$$
E(\Theta) =E\left((1-a)\cdot\Theta_1 +a\cdot \Theta_2\right)=\theta.
$$

efectivamente 

$E(\Theta)=(1-a)\cdot E(\Theta_1) +a\cdot E(\Theta_2)=(1-a)\cdot theta +a\cdot theta=\theta.$

## Solución ejercicio 3
Como $X_1,\ldots,X_{2n}$ una muestra aleatoria simple de una variable
aleatoria $N(\mu,\sigma)$. Sabemos que  $\sum_{i=1}^{2\cdot n} X_i$ sigue una ley $N\left(2\cdot n\cdot\mu, \sqrt{n \cdot\sigma^2}\right)$ luego $E\left(\sum_{i=1}^{2\cdot n} X_i\right)=2\cdot n\cdot \mu$, $Var(\sum_{i=1}^{2\cdot n} X_i)=2\cdot n\cdot \sigma^2$ y $E\left(\left(\sum_{i=1}^{2\cdot n}\right)^2\right)=2\cdot n\cdot \sigma^2+2\cdot n\mu^2.$ 

Entonces 

$$
\begin{array}{rl}
E(T)&=E\left(C\cdot\left(\left(\sum_{i=1}^{2n} X_i\right)^2- 4 n\sum_{i=1}^{n}
X_{2i} X_{2i-1}\right)\right)\\
& =C\cdot \left(2\cdot n\cdot\sigma^2+(2\cdot n\cdot\mu)^2-4\cdot n\cdot n\cdot \mu^2\right)\\
& = C\cdot2\cdot n\cdot\sigma^2
\end{array}
$$

Por lo que el valor de $C$ pedido es la socuión de la ecuación 
$$
C\cdot 2\cdot n\cdot\sigma^2=\sigma^2$$


despejando $C$ obtenemos que el valor buscado es $C=\frac{1}{2\cdot n}.$



## Ejercicio 4
Una variable aleatoria $X$ sigue la  distribución de 
Rayleigh con parámetro $\theta >0$ si es una variable 
aleatoria con valores $x>0$ y  función  de densidad:
$$
f(x)=\frac{x}{\theta} e^{-\frac{x^2}{2\theta}}.
$$

> Hallar estimadores del parámetro $\theta$:

>>   a.) El método de los momentos.

>>   b.) El método de la máxima  verosimilitud.

## Ejercicio 5
Sea $X$ una variable aleatoria tal que $E(X)=\mu$ y  $Var(X)=\sigma^2$. Sea $X_1,X_2$ una muestra aleatoria simple de $X$ de
tamaño $2$. Consideremos el siguiente estimador del parámetro $\mu$:
$\tilde{\mu}=2 a X_1 + (1-2 a) X_2$.  Hallar el valor de $a$ que hace que el estadístico  
$\tilde{\mu}$ sea el más eficiente posible.


